{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Embeddings\n",
    "\n",
    "Word embeddings are a pivotal concept in Natural Language Processing (NLP) that enable the representation of words as numerical vectors in a continuous vector space. This approach captures the semantic meaning of words based on their context within a corpus, allowing for more nuanced understanding and processing of language. Unlike traditional methods such as one-hot encoding, which treat words as distinct and unrelated entities, word embeddings facilitate the representation of words in a way that reflects their relationships and similarities.\n",
    "\n",
    "The development of word embeddings has transformed how machines understand language, making it possible to capture complex linguistic patterns. One of the most notable techniques for generating word embeddings is Word2Vec, introduced by Tomas Mikolov and his team at Google in 2013. Word2Vec employs neural networks to learn word representations from large text corpora, using methods like the Skip-Gram and Continuous Bag of Words (CBOW) models. These models effectively predict word occurrences based on their context, enabling the creation of dense vector representations that encapsulate semantic relationships.\n",
    "\n",
    "Word embeddings have numerous applications in NLP tasks, including sentiment analysis, machine translation, and information retrieval. They allow algorithms to perform vector arithmetic on words, revealing intriguing relationships—such as the famous example where \"king\" minus \"man\" plus \"woman\" results in a vector close to \"queen.\" This capability highlights how word embeddings can capture not just meanings but also contextual nuances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word2Vec is a groundbreaking technique in natural language processing that transforms words into continuous vector representations, capturing their meanings and relationships within a given context. Developed by researchers at Google in 2013, Word2Vec employs a shallow neural network model to analyze large corpora of text, enabling computers to understand linguistic nuances and semantic similarities among words.\n",
    "The primary goal of Word2Vec is to represent each word as a point in a high-dimensional space, where the spatial proximity of these points reflects the semantic relationships between the words. For instance, words that frequently appear in similar contexts are positioned closer together in this vector space, facilitating the discovery of relationships such as synonyms or analogies (e.g., \"king\" - \"man\" + \"woman\" = \"queen\").\n",
    "Word2Vec operates through two main architectures: the Continuous Bag-of-Words (CBOW) model, which predicts a target word based on its surrounding context, and the Skip-Gram model, which does the opposite by predicting context words given a target word. This flexibility allows Word2Vec to effectively learn from diverse datasets while maintaining computational efficiency.\n",
    "The introduction of Word2Vec has significantly enhanced various applications in natural language processing, including search engines, sentiment analysis, and recommendation systems, by providing a robust framework for understanding and manipulating language data in a way that was not previously possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Using cached gensim-4.3.3-cp312-cp312-macosx_11_0_arm64.whl.metadata (8.1 kB)\n",
      "Collecting numpy<2.0,>=1.18.5 (from gensim)\n",
      "  Using cached numpy-1.26.4-cp312-cp312-macosx_11_0_arm64.whl.metadata (61 kB)\n",
      "Collecting scipy<1.14.0,>=1.7.0 (from gensim)\n",
      "  Using cached scipy-1.13.1-cp312-cp312-macosx_12_0_arm64.whl.metadata (60 kB)\n",
      "Collecting smart-open>=1.8.1 (from gensim)\n",
      "  Using cached smart_open-7.0.5-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting wrapt (from smart-open>=1.8.1->gensim)\n",
      "  Using cached wrapt-1.17.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.4 kB)\n",
      "Using cached gensim-4.3.3-cp312-cp312-macosx_11_0_arm64.whl (24.0 MB)\n",
      "Using cached numpy-1.26.4-cp312-cp312-macosx_11_0_arm64.whl (13.7 MB)\n",
      "Using cached scipy-1.13.1-cp312-cp312-macosx_12_0_arm64.whl (30.4 MB)\n",
      "Using cached smart_open-7.0.5-py3-none-any.whl (61 kB)\n",
      "Using cached wrapt-1.17.0-cp312-cp312-macosx_11_0_arm64.whl (38 kB)\n",
      "Installing collected packages: wrapt, numpy, smart-open, scipy, gensim\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.1.3\n",
      "    Uninstalling numpy-2.1.3:\n",
      "      Successfully uninstalled numpy-2.1.3\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.14.1\n",
      "    Uninstalling scipy-1.14.1:\n",
      "      Successfully uninstalled scipy-1.14.1\n",
      "Successfully installed gensim-4.3.3 numpy-1.26.4 scipy-1.13.1 smart-open-7.0.5 wrapt-1.17.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gensim\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gensim is an open-source Python library specifically designed for natural language processing (NLP) tasks, particularly focusing on unsupervised topic modeling and document similarity analysis. Developed by Radim Řehůřek and first released in 2009, Gensim has become a vital tool for researchers and practitioners in the field of text mining and semantic analysis.\n",
    "\n",
    "Key Features:\n",
    "\n",
    "1: Unsupervised Learning: Gensim employs unsupervised machine learning algorithms to analyze large volumes of text data without the need for labeled training sets. This allows it to automatically identify patterns and themes within the data.\n",
    "\n",
    "2: Scalability: One of Gensim's standout features is its ability to handle large text corpora efficiently. It utilizes data streaming techniques, meaning that it can process datasets that exceed the available RAM, making it suitable for web-scale applications.\n",
    "\n",
    "3: Versatile Algorithms: The library includes implementations of popular algorithms such as Word2Vec, Doc2Vec, Latent Dirichlet Allocation (LDA), and Latent Semantic Analysis (LSA). These algorithms are essential for tasks like document clustering, topic extraction, and semantic similarity measurement.\n",
    "\n",
    "4: Cross-Platform Compatibility: Gensim is compatible with various operating systems including Windows, macOS, and Linux, making it accessible to a wide range of users.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec, KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Reference: https://stackoverflow.com/questions/46433778/import-googlenews-vectors-negative300-bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "word_vector = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.25976562e-01  2.97851562e-02  8.60595703e-03  1.39648438e-01\n",
      " -2.56347656e-02 -3.61328125e-02  1.11816406e-01 -1.98242188e-01\n",
      "  5.12695312e-02  3.63281250e-01 -2.42187500e-01 -3.02734375e-01\n",
      " -1.77734375e-01 -2.49023438e-02 -1.67968750e-01 -1.69921875e-01\n",
      "  3.46679688e-02  5.21850586e-03  4.63867188e-02  1.28906250e-01\n",
      "  1.36718750e-01  1.12792969e-01  5.95703125e-02  1.36718750e-01\n",
      "  1.01074219e-01 -1.76757812e-01 -2.51953125e-01  5.98144531e-02\n",
      "  3.41796875e-01 -3.11279297e-02  1.04492188e-01  6.17675781e-02\n",
      "  1.24511719e-01  4.00390625e-01 -3.22265625e-01  8.39843750e-02\n",
      "  3.90625000e-02  5.85937500e-03  7.03125000e-02  1.72851562e-01\n",
      "  1.38671875e-01 -2.31445312e-01  2.83203125e-01  1.42578125e-01\n",
      "  3.41796875e-01 -2.39257812e-02 -1.09863281e-01  3.32031250e-02\n",
      " -5.46875000e-02  1.53198242e-02 -1.62109375e-01  1.58203125e-01\n",
      " -2.59765625e-01  2.01416016e-02 -1.63085938e-01  1.35803223e-03\n",
      " -1.44531250e-01 -5.68847656e-02  4.29687500e-02 -2.46582031e-02\n",
      "  1.85546875e-01  4.47265625e-01  9.58251953e-03  1.31835938e-01\n",
      "  9.86328125e-02 -1.85546875e-01 -1.00097656e-01 -1.33789062e-01\n",
      " -1.25000000e-01  2.83203125e-01  1.23046875e-01  5.32226562e-02\n",
      " -1.77734375e-01  8.59375000e-02 -2.18505859e-02  2.05078125e-02\n",
      " -1.39648438e-01  2.51464844e-02  1.38671875e-01 -1.05468750e-01\n",
      "  1.38671875e-01  8.88671875e-02 -7.51953125e-02 -2.13623047e-02\n",
      "  1.72851562e-01  4.63867188e-02 -2.65625000e-01  8.91113281e-03\n",
      "  1.49414062e-01  3.78417969e-02  2.38281250e-01 -1.24511719e-01\n",
      " -2.17773438e-01 -1.81640625e-01  2.97851562e-02  5.71289062e-02\n",
      " -2.89306641e-02  1.24511719e-02  9.66796875e-02 -2.31445312e-01\n",
      "  5.81054688e-02  6.68945312e-02  7.08007812e-02 -3.08593750e-01\n",
      " -2.14843750e-01  1.45507812e-01 -4.27734375e-01 -9.39941406e-03\n",
      "  1.54296875e-01 -7.66601562e-02  2.89062500e-01  2.77343750e-01\n",
      " -4.86373901e-04 -1.36718750e-01  3.24218750e-01 -2.46093750e-01\n",
      " -3.03649902e-03 -2.11914062e-01  1.25000000e-01  2.69531250e-01\n",
      "  2.04101562e-01  8.25195312e-02 -2.01171875e-01 -1.60156250e-01\n",
      " -3.78417969e-02 -1.20117188e-01  1.15234375e-01 -4.10156250e-02\n",
      " -3.95507812e-02 -8.98437500e-02  6.34765625e-03  2.03125000e-01\n",
      "  1.86523438e-01  2.73437500e-01  6.29882812e-02  1.41601562e-01\n",
      " -9.81445312e-02  1.38671875e-01  1.82617188e-01  1.73828125e-01\n",
      "  1.73828125e-01 -2.37304688e-01  1.78710938e-01  6.34765625e-02\n",
      "  2.36328125e-01 -2.08984375e-01  8.74023438e-02 -1.66015625e-01\n",
      " -7.91015625e-02  2.43164062e-01 -8.88671875e-02  1.26953125e-01\n",
      " -2.16796875e-01 -1.73828125e-01 -3.59375000e-01 -8.25195312e-02\n",
      " -6.49414062e-02  5.07812500e-02  1.35742188e-01 -7.47070312e-02\n",
      " -1.64062500e-01  1.15356445e-02  4.45312500e-01 -2.15820312e-01\n",
      " -1.11328125e-01 -1.92382812e-01  1.70898438e-01 -1.25000000e-01\n",
      "  2.65502930e-03  1.92382812e-01 -1.74804688e-01  1.39648438e-01\n",
      "  2.92968750e-01  1.13281250e-01  5.95703125e-02 -6.39648438e-02\n",
      "  9.96093750e-02 -2.72216797e-02  1.96533203e-02  4.27246094e-02\n",
      " -2.46093750e-01  6.39648438e-02 -2.25585938e-01 -1.68945312e-01\n",
      "  2.89916992e-03  8.20312500e-02  3.41796875e-01  4.32128906e-02\n",
      "  1.32812500e-01  1.42578125e-01  7.61718750e-02  5.98144531e-02\n",
      " -1.19140625e-01  2.74658203e-03 -6.29882812e-02 -2.72216797e-02\n",
      " -4.82177734e-03 -8.20312500e-02 -2.49023438e-02 -4.00390625e-01\n",
      " -1.06933594e-01  4.24804688e-02  7.76367188e-02 -1.16699219e-01\n",
      "  7.37304688e-02 -9.22851562e-02  1.07910156e-01  1.58203125e-01\n",
      "  4.24804688e-02  1.26953125e-01  3.61328125e-02  2.67578125e-01\n",
      " -1.01074219e-01 -3.02734375e-01 -5.76171875e-02  5.05371094e-02\n",
      "  5.26428223e-04 -2.07031250e-01 -1.38671875e-01 -8.97216797e-03\n",
      " -2.78320312e-02 -1.41601562e-01  2.07031250e-01 -1.58203125e-01\n",
      "  1.27929688e-01  1.49414062e-01 -2.24609375e-02 -8.44726562e-02\n",
      "  1.22558594e-01  2.15820312e-01 -2.13867188e-01 -3.12500000e-01\n",
      " -3.73046875e-01  4.08935547e-03  1.07421875e-01  1.06933594e-01\n",
      "  7.32421875e-02  8.97216797e-03 -3.88183594e-02 -1.29882812e-01\n",
      "  1.49414062e-01 -2.14843750e-01 -1.83868408e-03  9.91210938e-02\n",
      "  1.57226562e-01 -1.14257812e-01 -2.05078125e-01  9.91210938e-02\n",
      "  3.69140625e-01 -1.97265625e-01  3.54003906e-02  1.09375000e-01\n",
      "  1.31835938e-01  1.66992188e-01  2.35351562e-01  1.04980469e-01\n",
      " -4.96093750e-01 -1.64062500e-01 -1.56250000e-01 -5.22460938e-02\n",
      "  1.03027344e-01  2.43164062e-01 -1.88476562e-01  5.07812500e-02\n",
      " -9.37500000e-02 -6.68945312e-02  2.27050781e-02  7.61718750e-02\n",
      "  2.89062500e-01  3.10546875e-01 -5.37109375e-02  2.28515625e-01\n",
      "  2.51464844e-02  6.78710938e-02 -1.21093750e-01 -2.15820312e-01\n",
      " -2.73437500e-01 -3.07617188e-02 -3.37890625e-01  1.53320312e-01\n",
      "  2.33398438e-01 -2.08007812e-01  3.73046875e-01  8.20312500e-02\n",
      "  2.51953125e-01 -7.61718750e-02 -4.66308594e-02 -2.23388672e-02\n",
      "  2.99072266e-02 -5.93261719e-02 -4.66918945e-03 -2.44140625e-01\n",
      " -2.09960938e-01 -2.87109375e-01 -4.54101562e-02 -1.77734375e-01\n",
      " -2.79296875e-01 -8.59375000e-02  9.13085938e-02  2.51953125e-01]\n"
     ]
    }
   ],
   "source": [
    "vec_king = word_vector['king']\n",
    "print(vec_king)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vec_king)\n",
    "vec_king.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(vec_king)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3.67187500e-01 -1.21582031e-01  2.85156250e-01  8.15429688e-02\n",
      "  3.19824219e-02 -3.19824219e-02  1.34765625e-01 -2.73437500e-01\n",
      "  9.46044922e-03 -1.07421875e-01  2.48046875e-01 -6.05468750e-01\n",
      "  5.02929688e-02  2.98828125e-01  9.57031250e-02  1.39648438e-01\n",
      " -5.41992188e-02  2.91015625e-01  2.85156250e-01  1.51367188e-01\n",
      " -2.89062500e-01 -3.46679688e-02  1.81884766e-02 -3.92578125e-01\n",
      "  2.46093750e-01  2.51953125e-01 -9.86328125e-02  3.22265625e-01\n",
      "  4.49218750e-01 -1.36718750e-01 -2.34375000e-01  4.12597656e-02\n",
      " -2.15820312e-01  1.69921875e-01  2.56347656e-02  1.50146484e-02\n",
      " -3.75976562e-02  6.95800781e-03  4.00390625e-01  2.09960938e-01\n",
      "  1.17675781e-01 -4.19921875e-02  2.34375000e-01  2.03125000e-01\n",
      " -1.86523438e-01 -2.46093750e-01  3.12500000e-01 -2.59765625e-01\n",
      " -1.06933594e-01  1.04003906e-01 -1.79687500e-01  5.71289062e-02\n",
      " -7.41577148e-03 -5.59082031e-02  7.61718750e-02 -4.14062500e-01\n",
      " -3.65234375e-01 -3.35937500e-01 -1.54296875e-01 -2.39257812e-01\n",
      " -3.73046875e-01  2.27355957e-03 -3.51562500e-01  8.64257812e-02\n",
      "  1.26953125e-01  2.21679688e-01 -9.86328125e-02  1.08886719e-01\n",
      "  3.65234375e-01 -5.66406250e-02  5.66406250e-02 -1.09375000e-01\n",
      " -1.66992188e-01 -4.54101562e-02 -2.00195312e-01 -1.22558594e-01\n",
      "  1.31835938e-01 -1.31835938e-01  1.03027344e-01 -3.41796875e-01\n",
      " -1.57226562e-01  2.04101562e-01  4.39453125e-02  2.44140625e-01\n",
      " -3.19824219e-02  3.20312500e-01 -4.41894531e-02  1.08398438e-01\n",
      " -4.98046875e-02 -9.52148438e-03  2.46093750e-01 -5.59082031e-02\n",
      "  4.07714844e-02 -1.78222656e-02 -2.95410156e-02  1.65039062e-01\n",
      "  5.03906250e-01 -2.81250000e-01  9.81445312e-02  1.80664062e-02\n",
      " -1.83593750e-01  2.53906250e-01  2.25585938e-01  1.63574219e-02\n",
      "  1.81640625e-01  1.38671875e-01  3.33984375e-01  1.39648438e-01\n",
      "  1.45874023e-02 -2.89306641e-02 -8.39843750e-02  1.50390625e-01\n",
      "  1.67968750e-01  2.28515625e-01  3.59375000e-01  1.22558594e-01\n",
      " -3.28125000e-01 -1.56250000e-01  2.77343750e-01  1.77001953e-02\n",
      " -1.46484375e-01 -4.51660156e-03 -4.46777344e-02  1.75781250e-01\n",
      " -3.75000000e-01  1.16699219e-01 -1.39648438e-01  2.55859375e-01\n",
      " -1.96289062e-01 -2.57568359e-02 -5.41992188e-02 -2.51464844e-02\n",
      " -1.93359375e-01 -3.17382812e-02 -8.74023438e-02 -1.32812500e-01\n",
      " -2.12402344e-02  4.33593750e-01 -5.20019531e-02  3.46679688e-02\n",
      "  8.00781250e-02  3.41796875e-02  1.99218750e-01 -2.39257812e-02\n",
      " -2.37304688e-01  1.93359375e-01  7.32421875e-02 -2.87109375e-01\n",
      "  1.25000000e-01  8.44726562e-02  1.30859375e-01 -2.19726562e-01\n",
      " -1.61132812e-01 -2.63671875e-01 -5.46875000e-01 -2.96875000e-01\n",
      "  3.44238281e-02 -2.87109375e-01 -1.93359375e-01 -1.61132812e-01\n",
      " -3.84765625e-01 -2.14843750e-01 -6.22558594e-03 -1.27929688e-01\n",
      " -1.00097656e-01 -6.21093750e-01  3.78906250e-01 -4.58984375e-01\n",
      "  1.44531250e-01 -9.13085938e-02 -3.08593750e-01  2.23632812e-01\n",
      "  7.86132812e-02 -2.16796875e-01  8.78906250e-02 -1.66992188e-01\n",
      "  1.14746094e-02 -2.53906250e-01 -6.25000000e-02  6.04248047e-03\n",
      "  1.56250000e-01  4.37500000e-01 -2.23632812e-01 -2.32421875e-01\n",
      "  2.75390625e-01  2.39257812e-01  4.49218750e-02 -7.51953125e-02\n",
      "  5.74218750e-01 -2.61230469e-02 -1.21582031e-01  2.44140625e-01\n",
      " -3.37890625e-01  8.59375000e-02 -7.71484375e-02  4.85839844e-02\n",
      "  1.43554688e-01  4.25781250e-01 -4.29687500e-02 -1.08398438e-01\n",
      "  1.19628906e-01 -1.91406250e-01 -2.12890625e-01 -2.87109375e-01\n",
      " -1.14746094e-01 -2.04101562e-01 -2.06298828e-02 -2.53906250e-01\n",
      "  8.25195312e-02 -3.97949219e-02 -1.57226562e-01  1.34765625e-01\n",
      "  2.08007812e-01 -1.78710938e-01 -2.00195312e-02 -8.34960938e-02\n",
      " -1.20605469e-01  4.29687500e-02 -1.94335938e-01 -1.32812500e-01\n",
      " -2.17285156e-02 -2.35351562e-01 -3.63281250e-01  1.51367188e-01\n",
      "  9.32617188e-02  1.63085938e-01  1.02050781e-01 -4.27734375e-01\n",
      "  2.83203125e-01  2.74658203e-04 -3.20312500e-01  1.68457031e-02\n",
      "  4.06250000e-01 -5.24902344e-02  7.91015625e-02 -1.41601562e-01\n",
      "  5.27343750e-01 -1.26953125e-01  4.74609375e-01 -6.64062500e-02\n",
      "  3.41796875e-01 -1.78710938e-01  3.69140625e-01 -2.05078125e-01\n",
      "  5.82885742e-03 -1.84570312e-01 -8.88671875e-02 -1.81640625e-01\n",
      " -4.80957031e-02  4.39453125e-01  2.12890625e-01 -3.07617188e-02\n",
      "  9.32617188e-02  2.40234375e-01  2.39257812e-01  2.51953125e-01\n",
      " -1.98974609e-02  1.24511719e-01 -4.73632812e-02 -2.13623047e-02\n",
      "  3.12500000e-02  3.05175781e-02  2.79296875e-01  9.08203125e-02\n",
      " -2.02148438e-01 -2.19726562e-02 -2.63671875e-01  8.78906250e-02\n",
      " -1.07421875e-01 -2.49023438e-01 -1.22070312e-02  1.73828125e-01\n",
      " -9.91210938e-02  7.27539062e-02  2.59765625e-01 -4.60937500e-01\n",
      "  3.59375000e-01 -2.25585938e-01  1.87988281e-02 -2.19726562e-01\n",
      " -2.08984375e-01 -1.51367188e-01  8.64257812e-02  1.11694336e-02\n",
      "  6.93359375e-02 -2.99072266e-02  1.43554688e-01  1.89453125e-01\n",
      " -1.32812500e-01  4.72656250e-01 -1.40625000e-01 -2.52685547e-02\n",
      "  1.91406250e-01 -2.63671875e-01 -1.39648438e-01  1.09375000e-01\n",
      "  1.97753906e-02  2.49023438e-01 -1.42578125e-01  4.15039062e-02]\n"
     ]
    }
   ],
   "source": [
    "vec_cricket = word_vector['cricket']\n",
    "print(vec_cricket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cricketing', 0.8372224569320679),\n",
       " ('cricketers', 0.8165745139122009),\n",
       " ('Test_cricket', 0.8094819188117981),\n",
       " ('Twenty##_cricket', 0.8068488240242004),\n",
       " ('Twenty##', 0.7624265551567078),\n",
       " ('Cricket', 0.75413978099823),\n",
       " ('cricketer', 0.7372578382492065),\n",
       " ('twenty##', 0.7316356897354126),\n",
       " ('T##_cricket', 0.7304614186286926),\n",
       " ('West_Indies_cricket', 0.6987985968589783)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vector.most_similar('cricket')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('glad', 0.7408890724182129),\n",
       " ('pleased', 0.6632170677185059),\n",
       " ('ecstatic', 0.6626912355422974),\n",
       " ('overjoyed', 0.6599286794662476),\n",
       " ('thrilled', 0.6514049172401428),\n",
       " ('satisfied', 0.6437949538230896),\n",
       " ('proud', 0.636042058467865),\n",
       " ('delighted', 0.627237856388092),\n",
       " ('disappointed', 0.6269949674606323),\n",
       " ('excited', 0.6247665286064148)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vector.most_similar('happy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Battochio', 0.48897770047187805),\n",
       " ('Ted_Donato', 0.46019503474235535),\n",
       " ('coach_Benoit_Groulx', 0.4598839581012726),\n",
       " ('Beskorowany', 0.45813873410224915),\n",
       " ('Siskins', 0.4557701349258423),\n",
       " ('Kitchener_Rangers', 0.4521059989929199),\n",
       " ('Jyri_Niemi', 0.4515666365623474),\n",
       " ('Grubauer', 0.45036473870277405),\n",
       " ('Cullitons', 0.4500056803226471),\n",
       " ('Cunneyworth', 0.44906681776046753)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vector.most_similar('hockey','sports')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "unknown_vector = word_vector['king'] - word_vector['man'] + word_vector['woman']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('king', 0.8449392318725586),\n",
       " ('queen', 0.7300516366958618),\n",
       " ('monarch', 0.6454660296440125),\n",
       " ('princess', 0.6156251430511475),\n",
       " ('crown_prince', 0.5818676948547363),\n",
       " ('prince', 0.5777117609977722),\n",
       " ('kings', 0.5613663792610168),\n",
       " ('sultan', 0.5376776456832886),\n",
       " ('Queen_Consort', 0.5344247817993164),\n",
       " ('queens', 0.5289887189865112)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vector.most_similar(unknown_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
