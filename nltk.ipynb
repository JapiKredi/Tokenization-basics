{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: click in /Users/jasper/Desktop/Introduction_AIML/venv/lib/python3.12/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /Users/jasper/Desktop/Introduction_AIML/venv/lib/python3.12/site-packages (from nltk) (1.4.2)\n",
      "Collecting regex>=2021.8.3 (from nltk)\n",
      "  Downloading regex-2024.11.6-cp312-cp312-macosx_11_0_arm64.whl.metadata (40 kB)\n",
      "Collecting tqdm (from nltk)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading regex-2024.11.6-cp312-cp312-macosx_11_0_arm64.whl (284 kB)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: tqdm, regex, nltk\n",
      "Successfully installed nltk-3.9.1 regex-2024.11.6 tqdm-4.67.1\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'all'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package abc to /Users/jasper/nltk_data...\n",
      "[nltk_data]    |   Package abc is already up-to-date!\n",
      "[nltk_data]    | Downloading package alpino to\n",
      "[nltk_data]    |     /Users/jasper/nltk_data...\n",
      "[nltk_data]    |   Package alpino is already up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     /Users/jasper/nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]    |     /Users/jasper/nltk_data...\n",
      "[nltk_data]    |   Unzipping\n",
      "[nltk_data]    |       taggers/averaged_perceptron_tagger_eng.zip.\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
      "[nltk_data]    |     /Users/jasper/nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger_ru is already\n",
      "[nltk_data]    |       up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_rus to\n",
      "[nltk_data]    |     /Users/jasper/nltk_data...\n",
      "[nltk_data]    |   Unzipping\n",
      "[nltk_data]    |       taggers/averaged_perceptron_tagger_rus.zip.\n",
      "[nltk_data]    | Downloading package basque_grammars to\n",
      "[nltk_data]    |     /Users/jasper/nltk_data...\n",
      "[nltk_data]    |   Package basque_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package bcp47 to\n",
      "[nltk_data]    |     /Users/jasper/nltk_data...\n",
      "[nltk_data]    |   Package bcp47 is already up-to-date!\n",
      "[nltk_data]    | Downloading package biocreative_ppi to\n",
      "[nltk_data]    |     /Users/jasper/nltk_data...\n",
      "[nltk_data]    |   Package biocreative_ppi is already up-to-date!\n",
      "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
      "[nltk_data]    |     /Users/jasper/nltk_data...\n",
      "[nltk_data]    |   Package bllip_wsj_no_aux is already up-to-date!\n",
      "[nltk_data]    | Downloading package book_grammars to\n",
      "[nltk_data]    |     /Users/jasper/nltk_data...\n",
      "[nltk_data]    |   Package book_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown to\n",
      "[nltk_data]    |     /Users/jasper/nltk_data...\n",
      "[nltk_data]    |   Package brown is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown_tei to\n",
      "[nltk_data]    |     /Users/jasper/nltk_data...\n",
      "[nltk_data]    |   Package brown_tei is already up-to-date!\n",
      "[nltk_data]    | Downloading package cess_cat to\n",
      "[nltk_data]    |     /Users/jasper/nltk_data...\n",
      "[nltk_data]    |   Package cess_cat is already up-to-date!\n",
      "[nltk_data]    | Downloading package cess_esp to\n",
      "[nltk_data]    |     /Users/jasper/nltk_data...\n",
      "[nltk_data]    |   Package cess_esp is already up-to-date!\n",
      "[nltk_data]    | Downloading package chat80 to\n",
      "[nltk_data]    |     /Users/jasper/nltk_data...\n",
      "[nltk_data]    |   Package chat80 is already up-to-date!\n",
      "[nltk_data]    | Downloading package city_database to\n",
      "[nltk_data]    |     /Users/jasper/nltk_data...\n",
      "[nltk_data]    |   Package city_database is already up-to-date!\n",
      "[nltk_data]    | Downloading package cmudict to\n",
      "[nltk_data]    |     /Users/jasper/nltk_data...\n",
      "[nltk_data]    |   Package cmudict is already up-to-date!\n",
      "[nltk_data]    | Downloading package comparative_sentences to\n",
      "[nltk_data]    |     /Users/jasper/nltk_data...\n",
      "[nltk_data]    |   Package comparative_sentences is already up-to-\n",
      "[nltk_data]    |       date!\n",
      "[nltk_data]    | Downloading package comtrans to\n",
      "[nltk_data]    |     /Users/jasper/nltk_data...\n",
      "[nltk_data]    |   Package comtrans is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2000 to\n",
      "[nltk_data]    |     /Users/jasper/nltk_data...\n",
      "[nltk_data]    |   Package conll2000 is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2002 to\n",
      "[nltk_data]    |     /Users/jasper/nltk_data...\n",
      "[nltk_data]    |   Package conll2002 is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2007 to\n",
      "[nltk_data]    |     /Users/jasper/nltk_data...\n",
      "[nltk_data]    |   Package conll2007 is already up-to-date!\n",
      "[nltk_data]    | Downloading package crubadan to\n",
      "[nltk_data]    |     /Users/jasper/nltk_data...\n",
      "[nltk_data]    |   Package crubadan is already up-to-date!\n",
      "[nltk_data]    | Downloading package dependency_treebank to\n",
      "[nltk_data]    |     /Users/jasper/nltk_data...\n",
      "[nltk_data]    |   Package dependency_treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package dolch to\n",
      "[nltk_data]    |     /Users/jasper/nltk_data...\n",
      "[nltk_data]    |   Package dolch is already up-to-date!\n",
      "[nltk_data]    | Downloading package europarl_raw to\n",
      "[nltk_data]    |     /Users/jasper/nltk_data...\n",
      "[nltk_data]    |   Package europarl_raw is already up-to-date!\n",
      "[nltk_data]    | Downloading package extended_omw to\n",
      "[nltk_data]    |     /Users/jasper/nltk_data...\n",
      "[nltk_data]    |   Package extended_omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package floresta to\n",
      "[nltk_data]    |     /Users/jasper/nltk_data...\n",
      "[nltk_data]    |   Package floresta is already up-to-date!\n",
      "[nltk_data]    | Downloading package framenet_v15 to\n",
      "[nltk_data]    |     /Users/jasper/nltk_data...\n",
      "[nltk_data]    |   Package framenet_v15 is already up-to-date!\n",
      "[nltk_data]    | Downloading package framenet_v17 to\n",
      "[nltk_data]    |     /Users/jasper/nltk_data...\n",
      "[nltk_data]    |   Package framenet_v17 is already up-to-date!\n",
      "[nltk_data]    | Downloading package gazetteers to\n",
      "[nltk_data]    |     /Users/jasper/nltk_data...\n",
      "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
      "[nltk_data]    | Downloading package genesis to\n",
      "[nltk_data]    |     /Users/jasper/nltk_data...\n",
      "[nltk_data]    |   Package genesis is already up-to-date!\n",
      "[nltk_data]    | Downloading package gutenberg to\n",
      "[nltk_data]    |     /Users/jasper/nltk_data...\n",
      "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
      "[nltk_data]    | Downloading package ieer to\n",
      "[nltk_data]    |     /Users/jasper/nltk_data...\n",
      "[nltk_data]    |   Package ieer is already up-to-date!\n",
      "[nltk_data]    | Downloading package inaugural to\n",
      "[nltk_data]    |     /Users/jasper/nltk_data...\n",
      "[nltk_data]    |   Package inaugural is already up-to-date!\n",
      "[nltk_data]    | Downloading package indian to\n",
      "[nltk_data]    |     /Users/jasper/nltk_data...\n",
      "[nltk_data]    |   Package indian is already up-to-date!\n",
      "[nltk_data]    | Downloading package jeita to\n",
      "[nltk_data]    |     /Users/jasper/nltk_data...\n",
      "[nltk_data]    |   Package jeita is already up-to-date!\n",
      "[nltk_data]    | Downloading package kimmo to\n",
      "[nltk_data]    |     /Users/jasper/nltk_data...\n",
      "[nltk_data]    |   Package kimmo is already up-to-date!\n",
      "[nltk_data]    | Downloading package knbc to\n",
      "[nltk_data]    |     /Users/jasper/nltk_data...\n",
      "[nltk_data]    |   Package knbc is already up-to-date!\n",
      "[nltk_data]    | Downloading package large_grammars to\n",
      "[nltk_data]    |     /Users/jasper/nltk_data...\n",
      "[nltk_data]    |   Package large_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package lin_thesaurus to\n",
      "[nltk_data]    |     /Users/jasper/nltk_data...\n",
      "[nltk_data]    |   Package lin_thesaurus is already up-to-date!\n",
      "[nltk_data]    | Downloading package mac_morpho to\n",
      "[nltk_data]    |     /Users/jasper/nltk_data...\n",
      "[nltk_data]    |   Package mac_morpho is already up-to-date!\n",
      "[nltk_data]    | Downloading package machado to\n",
      "[nltk_data]    |     /Users/jasper/nltk_data...\n",
      "[nltk_data]    |   Package machado is already up-to-date!\n",
      "[nltk_data]    | Downloading package masc_tagged to\n",
      "[nltk_data]    |     /Users/jasper/nltk_data...\n",
      "[nltk_data]    |   Package masc_tagged is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     /Users/jasper/nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker_tab to\n",
      "[nltk_data]    |     /Users/jasper/nltk_data...\n",
      "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker_tab.zip.\n",
      "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
      "[nltk_data]    |     /Users/jasper/nltk_data...\n",
      "[nltk_data]    |   Package maxent_treebank_pos_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | Downloading package maxent_treebank_pos_tagger_tab to\n",
      "[nltk_data]    |     /Users/jasper/nltk_data...\n",
      "[nltk_data]    |   Unzipping\n",
      "[nltk_data]    |       taggers/maxent_treebank_pos_tagger_tab.zip.\n",
      "[nltk_data]    | Downloading package moses_sample to\n",
      "[nltk_data]    |     /Users/jasper/nltk_data...\n",
      "[nltk_data]    |   Package moses_sample is already up-to-date!\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     /Users/jasper/nltk_data...\n",
      "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
      "[nltk_data]    | Downloading package mte_teip5 to\n",
      "[nltk_data]    |     /Users/jasper/nltk_data...\n",
      "[nltk_data]    |   Package mte_teip5 is already up-to-date!\n",
      "[nltk_data]    | Downloading package mwa_ppdb to\n",
      "[nltk_data]    |     /Users/jasper/nltk_data...\n",
      "[nltk_data]    |   Package mwa_ppdb is already up-to-date!\n",
      "[nltk_data]    | Downloading package names to\n",
      "[nltk_data]    |     /Users/jasper/nltk_data...\n",
      "[nltk_data]    |   Package names is already up-to-date!\n",
      "[nltk_data]    | Downloading package nombank.1.0 to\n",
      "[nltk_data]    |     /Users/jasper/nltk_data...\n",
      "[nltk_data]    |   Package nombank.1.0 is already up-to-date!\n",
      "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
      "[nltk_data]    |     /Users/jasper/nltk_data...\n",
      "[nltk_data]    |   Package nonbreaking_prefixes is already up-to-date!\n",
      "[nltk_data]    | Downloading package nps_chat to\n",
      "[nltk_data]    |     /Users/jasper/nltk_data...\n",
      "[nltk_data]    |   Package nps_chat is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw to /Users/jasper/nltk_data...\n",
      "[nltk_data]    |   Package omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw-1.4 to\n",
      "[nltk_data]    |     /Users/jasper/nltk_data...\n",
      "[nltk_data]    |   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data]    | Downloading package opinion_lexicon to\n",
      "[nltk_data]    |     /Users/jasper/nltk_data...\n",
      "[nltk_data]    |   Package opinion_lexicon is already up-to-date!\n",
      "[nltk_data]    | Downloading package panlex_swadesh to\n",
      "[nltk_data]    |     /Users/jasper/nltk_data...\n",
      "[nltk_data]    |   Package panlex_swadesh is already up-to-date!\n",
      "[nltk_data]    | Downloading package paradigms to\n",
      "[nltk_data]    |     /Users/jasper/nltk_data...\n",
      "[nltk_data]    |   Package paradigms is already up-to-date!\n",
      "[nltk_data]    | Downloading package pe08 to\n",
      "[nltk_data]    |     /Users/jasper/nltk_data...\n",
      "[nltk_data]    |   Package pe08 is already up-to-date!\n",
      "[nltk_data]    | Downloading package perluniprops to\n",
      "[nltk_data]    |     /Users/jasper/nltk_data...\n",
      "[nltk_data]    |   Package perluniprops is already up-to-date!\n",
      "[nltk_data]    | Downloading package pil to /Users/jasper/nltk_data...\n",
      "[nltk_data]    |   Package pil is already up-to-date!\n",
      "[nltk_data]    | Downloading package pl196x to\n",
      "[nltk_data]    |     /Users/jasper/nltk_data...\n",
      "[nltk_data]    |   Package pl196x is already up-to-date!\n",
      "[nltk_data]    | Downloading package porter_test to\n",
      "[nltk_data]    |     /Users/jasper/nltk_data...\n",
      "[nltk_data]    |   Package porter_test is already up-to-date!\n",
      "[nltk_data]    | Downloading package ppattach to\n",
      "[nltk_data]    |     /Users/jasper/nltk_data...\n",
      "[nltk_data]    |   Package ppattach is already up-to-date!\n",
      "[nltk_data]    | Downloading package problem_reports to\n",
      "[nltk_data]    |     /Users/jasper/nltk_data...\n",
      "[nltk_data]    |   Package problem_reports is already up-to-date!\n",
      "[nltk_data]    | Downloading package product_reviews_1 to\n",
      "[nltk_data]    |     /Users/jasper/nltk_data...\n",
      "[nltk_data]    |   Package product_reviews_1 is already up-to-date!\n",
      "[nltk_data]    | Downloading package product_reviews_2 to\n",
      "[nltk_data]    |     /Users/jasper/nltk_data...\n",
      "[nltk_data]    |   Package product_reviews_2 is already up-to-date!\n",
      "[nltk_data]    | Downloading package propbank to\n",
      "[nltk_data]    |     /Users/jasper/nltk_data...\n",
      "[nltk_data]    |   Package propbank is already up-to-date!\n",
      "[nltk_data]    | Downloading package pros_cons to\n",
      "[nltk_data]    |     /Users/jasper/nltk_data...\n",
      "[nltk_data]    |   Package pros_cons is already up-to-date!\n",
      "[nltk_data]    | Downloading package ptb to /Users/jasper/nltk_data...\n",
      "[nltk_data]    |   Package ptb is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt to\n",
      "[nltk_data]    |     /Users/jasper/nltk_data...\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt_tab to\n",
      "[nltk_data]    |     /Users/jasper/nltk_data...\n",
      "[nltk_data]    |   Unzipping tokenizers/punkt_tab.zip.\n",
      "[nltk_data]    | Downloading package qc to /Users/jasper/nltk_data...\n",
      "[nltk_data]    |   Package qc is already up-to-date!\n",
      "[nltk_data]    | Downloading package reuters to\n",
      "[nltk_data]    |     /Users/jasper/nltk_data...\n",
      "[nltk_data]    |   Package reuters is already up-to-date!\n",
      "[nltk_data]    | Downloading package rslp to\n",
      "[nltk_data]    |     /Users/jasper/nltk_data...\n",
      "[nltk_data]    |   Package rslp is already up-to-date!\n",
      "[nltk_data]    | Downloading package rte to /Users/jasper/nltk_data...\n",
      "[nltk_data]    |   Package rte is already up-to-date!\n",
      "[nltk_data]    | Downloading package sample_grammars to\n",
      "[nltk_data]    |     /Users/jasper/nltk_data...\n",
      "[nltk_data]    |   Package sample_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package semcor to\n",
      "[nltk_data]    |     /Users/jasper/nltk_data...\n",
      "[nltk_data]    |   Package semcor is already up-to-date!\n",
      "[nltk_data]    | Downloading package senseval to\n",
      "[nltk_data]    |     /Users/jasper/nltk_data...\n",
      "[nltk_data]    |   Package senseval is already up-to-date!\n",
      "[nltk_data]    | Downloading package sentence_polarity to\n",
      "[nltk_data]    |     /Users/jasper/nltk_data...\n",
      "[nltk_data]    |   Package sentence_polarity is already up-to-date!\n",
      "[nltk_data]    | Downloading package sentiwordnet to\n",
      "[nltk_data]    |     /Users/jasper/nltk_data...\n",
      "[nltk_data]    |   Package sentiwordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package shakespeare to\n",
      "[nltk_data]    |     /Users/jasper/nltk_data...\n",
      "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
      "[nltk_data]    | Downloading package sinica_treebank to\n",
      "[nltk_data]    |     /Users/jasper/nltk_data...\n",
      "[nltk_data]    |   Package sinica_treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package smultron to\n",
      "[nltk_data]    |     /Users/jasper/nltk_data...\n",
      "[nltk_data]    |   Package smultron is already up-to-date!\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     /Users/jasper/nltk_data...\n",
      "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
      "[nltk_data]    | Downloading package spanish_grammars to\n",
      "[nltk_data]    |     /Users/jasper/nltk_data...\n",
      "[nltk_data]    |   Package spanish_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package state_union to\n",
      "[nltk_data]    |     /Users/jasper/nltk_data...\n",
      "[nltk_data]    |   Package state_union is already up-to-date!\n",
      "[nltk_data]    | Downloading package stopwords to\n",
      "[nltk_data]    |     /Users/jasper/nltk_data...\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\n",
      "[nltk_data]    | Downloading package subjectivity to\n",
      "[nltk_data]    |     /Users/jasper/nltk_data...\n",
      "[nltk_data]    |   Package subjectivity is already up-to-date!\n",
      "[nltk_data]    | Downloading package swadesh to\n",
      "[nltk_data]    |     /Users/jasper/nltk_data...\n",
      "[nltk_data]    |   Package swadesh is already up-to-date!\n",
      "[nltk_data]    | Downloading package switchboard to\n",
      "[nltk_data]    |     /Users/jasper/nltk_data...\n",
      "[nltk_data]    |   Package switchboard is already up-to-date!\n",
      "[nltk_data]    | Downloading package tagsets to\n",
      "[nltk_data]    |     /Users/jasper/nltk_data...\n",
      "[nltk_data]    |   Package tagsets is already up-to-date!\n",
      "[nltk_data]    | Downloading package tagsets_json to\n",
      "[nltk_data]    |     /Users/jasper/nltk_data...\n",
      "[nltk_data]    |   Unzipping help/tagsets_json.zip.\n",
      "[nltk_data]    | Downloading package timit to\n",
      "[nltk_data]    |     /Users/jasper/nltk_data...\n",
      "[nltk_data]    |   Package timit is already up-to-date!\n",
      "[nltk_data]    | Downloading package toolbox to\n",
      "[nltk_data]    |     /Users/jasper/nltk_data...\n",
      "[nltk_data]    |   Package toolbox is already up-to-date!\n",
      "[nltk_data]    | Downloading package treebank to\n",
      "[nltk_data]    |     /Users/jasper/nltk_data...\n",
      "[nltk_data]    |   Package treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     /Users/jasper/nltk_data...\n",
      "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package udhr to\n",
      "[nltk_data]    |     /Users/jasper/nltk_data...\n",
      "[nltk_data]    |   Package udhr is already up-to-date!\n",
      "[nltk_data]    | Downloading package udhr2 to\n",
      "[nltk_data]    |     /Users/jasper/nltk_data...\n",
      "[nltk_data]    |   Package udhr2 is already up-to-date!\n",
      "[nltk_data]    | Downloading package unicode_samples to\n",
      "[nltk_data]    |     /Users/jasper/nltk_data...\n",
      "[nltk_data]    |   Package unicode_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package universal_tagset to\n",
      "[nltk_data]    |     /Users/jasper/nltk_data...\n",
      "[nltk_data]    |   Package universal_tagset is already up-to-date!\n",
      "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
      "[nltk_data]    |     /Users/jasper/nltk_data...\n",
      "[nltk_data]    |   Package universal_treebanks_v20 is already up-to-\n",
      "[nltk_data]    |       date!\n",
      "[nltk_data]    | Downloading package vader_lexicon to\n",
      "[nltk_data]    |     /Users/jasper/nltk_data...\n",
      "[nltk_data]    |   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data]    | Downloading package verbnet to\n",
      "[nltk_data]    |     /Users/jasper/nltk_data...\n",
      "[nltk_data]    |   Package verbnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package verbnet3 to\n",
      "[nltk_data]    |     /Users/jasper/nltk_data...\n",
      "[nltk_data]    |   Package verbnet3 is already up-to-date!\n",
      "[nltk_data]    | Downloading package webtext to\n",
      "[nltk_data]    |     /Users/jasper/nltk_data...\n",
      "[nltk_data]    |   Package webtext is already up-to-date!\n",
      "[nltk_data]    | Downloading package wmt15_eval to\n",
      "[nltk_data]    |     /Users/jasper/nltk_data...\n",
      "[nltk_data]    |   Package wmt15_eval is already up-to-date!\n",
      "[nltk_data]    | Downloading package word2vec_sample to\n",
      "[nltk_data]    |     /Users/jasper/nltk_data...\n",
      "[nltk_data]    |   Package word2vec_sample is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet to\n",
      "[nltk_data]    |     /Users/jasper/nltk_data...\n",
      "[nltk_data]    |   Package wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet2021 to\n",
      "[nltk_data]    |     /Users/jasper/nltk_data...\n",
      "[nltk_data]    |   Package wordnet2021 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet2022 to\n",
      "[nltk_data]    |     /Users/jasper/nltk_data...\n",
      "[nltk_data]    |   Package wordnet2022 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet31 to\n",
      "[nltk_data]    |     /Users/jasper/nltk_data...\n",
      "[nltk_data]    |   Package wordnet31 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet_ic to\n",
      "[nltk_data]    |     /Users/jasper/nltk_data...\n",
      "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
      "[nltk_data]    | Downloading package words to\n",
      "[nltk_data]    |     /Users/jasper/nltk_data...\n",
      "[nltk_data]    |   Package words is already up-to-date!\n",
      "[nltk_data]    | Downloading package ycoe to\n",
      "[nltk_data]    |     /Users/jasper/nltk_data...\n",
      "[nltk_data]    |   Package ycoe is already up-to-date!\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection all\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['misc', 'tokenizers', '.DS_Store', 'stemmers', 'chunkers', 'models', 'nltk_data-gh-pages', 'grammars', 'taggers', 'sentiment', 'corpora', 'help']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import nltk\n",
    "\n",
    "# Set the NLTK_DATA environment variable\n",
    "os.environ['NLTK_DATA'] = '/Users/jasper/nltk_data'\n",
    "\n",
    "# Append the NLTK data path\n",
    "nltk.data.path.append('/Users/jasper/nltk_data')\n",
    "\n",
    "# List the contents of the NLTK data directory\n",
    "nltk_data_dir = '/Users/jasper/nltk_data'\n",
    "print(os.listdir(nltk_data_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['punkt', 'punkt_tab', 'punkt.zip', 'punkt_tab.zip']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "nltk_data_dir = '/Users/jasper/nltk_data/tokenizers'\n",
    "print(os.listdir(nltk_data_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello welcome to the world of programming.', 'Programming is fun and interesting.', 'Please do watch the entire course to get a good understanding']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/jasper/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import nltk\n",
    "from nltk.tokenize.punkt import PunktSentenceTokenizer\n",
    "\n",
    "# Set the NLTK_DATA environment variable\n",
    "os.environ['NLTK_DATA'] = '/Users/jasper/nltk_data'\n",
    "\n",
    "# Append the NLTK data path\n",
    "nltk.data.path.append('/Users/jasper/nltk_data')\n",
    "\n",
    "# Ensure the 'punkt' package is downloaded\n",
    "nltk.download('punkt', download_dir='/Users/jasper/nltk_data')\n",
    "\n",
    "corpus = \"Hello welcome to the world of programming. Programming is fun and interesting. Please do watch the entire course to get a good understanding\"\n",
    "\n",
    "## Tokenization\n",
    "tokenizer = PunktSentenceTokenizer()\n",
    "my_sentences = tokenizer.tokenize(corpus)\n",
    "print(my_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(my_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello welcome to the world of programming.\n",
      "Programming is fun and interesting.\n",
      "Please do watch the entire course to get a good understanding\n"
     ]
    }
   ],
   "source": [
    "for sentence in my_sentences:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', 'welcome', 'to', 'the', 'world', 'of', 'programming', '.', 'Programming', 'is', 'fun', 'and', 'interesting', '.', 'Please', 'do', 'watch', 'the', 'entire', 'course', 'to', 'get', 'a', 'good', 'understanding']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Set the NLTK_DATA environment variable to your working directory\n",
    "os.environ['NLTK_DATA'] = '/Users/jasper/Desktop/Tokenization-basics'\n",
    "\n",
    "# Append the NLTK data path\n",
    "nltk.data.path.append('/Users/jasper/Desktop/Tokenization-basics')\n",
    "\n",
    "# Manually load the punkt tokenizer\n",
    "nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "\n",
    "corpus = \"Hello welcome to the world of programming. Programming is fun and interesting. Please do watch the entire course to get a good understanding\"\n",
    "\n",
    "## Tokenization\n",
    "words = word_tokenize(corpus)\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', 'welcome', 'to', 'the', 'world', 'of', 'programming', '.']\n",
      "['Programming', 'is', 'fun', 'and', 'interesting', '.']\n",
      "['Please', 'do', 'watch', 'the', 'entire', 'course', 'to', 'get', 'a', 'good', 'understanding']\n"
     ]
    }
   ],
   "source": [
    "documents = sent_tokenize(corpus)\n",
    "\n",
    "for sentence in documents:\n",
    "    words = word_tokenize(sentence)\n",
    "    print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import wordpunct_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " 'welcome',\n",
       " 'to',\n",
       " 'the',\n",
       " 'world',\n",
       " 'of',\n",
       " 'programming',\n",
       " '.',\n",
       " 'Programming',\n",
       " 'is',\n",
       " 'fun',\n",
       " 'and',\n",
       " 'interesting',\n",
       " '.',\n",
       " 'Please',\n",
       " 'do',\n",
       " 'watch',\n",
       " 'the',\n",
       " 'entire',\n",
       " 'course',\n",
       " 'to',\n",
       " 'get',\n",
       " 'a',\n",
       " 'good',\n",
       " 'understanding']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordpunct_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " 'welcome',\n",
       " 'to',\n",
       " 'the',\n",
       " 'world',\n",
       " 'of',\n",
       " 'programming.',\n",
       " 'Programming',\n",
       " 'is',\n",
       " 'fun',\n",
       " 'and',\n",
       " 'interesting.',\n",
       " 'Please',\n",
       " 'do',\n",
       " 'watch',\n",
       " 'the',\n",
       " 'entire',\n",
       " 'course',\n",
       " 'to',\n",
       " 'get',\n",
       " 'a',\n",
       " 'good',\n",
       " 'understanding']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "tokenizer = TreebankWordTokenizer()\n",
    "tokenizer.tokenize(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stemming is a fundamental technique in Natural Language Processing (NLP) that focuses on reducing words to their base or root form, known as the \"stem.\" This process is essential for various NLP applications, including information retrieval, text analysis, and sentiment analysis. By simplifying words to their core components, stemming helps algorithms understand the underlying meaning of different word forms, which enhances the efficiency and effectiveness of language processing tasks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overview of Stemming\n",
    "\n",
    "The primary goal of stemming is to standardize words by removing prefixes and suffixes, thereby grouping related words together. For instance, the words \"running,\" \"runner,\" and \"ran\" can all be reduced to the stem \"run.\" This reduction allows NLP systems to treat these variations as equivalent, facilitating better understanding and retrieval of information.\n",
    "Stemming algorithms typically employ heuristic methods to achieve this reduction. One of the most widely used stemming algorithms is the Porter Stemmer, which applies a series of rules to trim word endings based on common suffix patterns. While stemming can significantly improve processing speed and reduce vocabulary size, it can also lead to challenges such as over-stemming (where distinct words are reduced to the same stem) and under-stemming (where similar words are not grouped together)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importance in NLP:\n",
    "\n",
    "Stemming plays a crucial role in enhancing the performance of NLP applications by:\n",
    "\n",
    "1: Reducing Complexity: By normalizing variations of words, stemming simplifies the linguistic data that algorithms must process.\n",
    "\n",
    "2: Improving Search Efficiency: In information retrieval systems, stemming helps match user queries with relevant documents by recognizing different forms of a word as equivalent.\n",
    "\n",
    "3: Facilitating Text Analysis: Stemming aids in identifying patterns and relationships within text data, making it easier to conduct tasks like sentiment analysis or topic modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stemming\n",
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ['running', 'runner', 'ran', 'runs', 'easily', 'fairly', \"eating\", 'eat', 'eater', 'ate', 'eats']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemming = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running-->run\n",
      "runner-->runner\n",
      "ran-->ran\n",
      "runs-->run\n",
      "easily-->easili\n",
      "fairly-->fairli\n",
      "eating-->eat\n",
      "eat-->eat\n",
      "eater-->eater\n",
      "ate-->ate\n",
      "eats-->eat\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word + \"-->\" + stemming.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The disadvantage of PorterStemming is that the root of the word can change\n",
    "# For example: \"easily\" becomes \"easili\" and \"fairly\" becomes \"fairli\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RegexStemmer Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RegexpStemmer class in Natural Language Processing (NLP) is a specialized stemming tool that utilizes regular expressions to identify and remove morphological affixes from words. This approach provides a flexible and customizable method for stemming, allowing users to define specific patterns that dictate how words should be reduced to their root forms. Unlike traditional stemming algorithms, which apply fixed rules, the RegexpStemmer enables the creation of tailored stemming rules that can accommodate the unique linguistic characteristics of different datasets or applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key Features of RegexpStemmer\n",
    "\n",
    "1: Customizable Patterns: Users can specify regular expressions to match various suffixes or prefixes they wish to remove from words. This feature is particularly beneficial in applications where standard stemming algorithms may not adequately address specific linguistic nuances.\n",
    "\n",
    "2: Morphological Affix Removal: The primary function of the RegexpStemmer is to strip away affixes from words based on the defined patterns. For example, a pattern like r'ing$|s$|e$|able$ would effectively remove common endings such as \"ing,\" \"s,\" \"e,\" and \"able\" from words, simplifying them to their base forms.\n",
    "\n",
    "3: Minimum Length Parameter: The RegexpStemmer includes a parameter that allows users to set a minimum length for words to be stemmed. This helps prevent the stemming of very short words that may not benefit from reduction, thus preserving their integrity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importance in NLP\n",
    "\n",
    "The RegexpStemmer is particularly useful in scenarios where standard stemming techniques may lead to over-stemming or under-stemming issues. By allowing for customized rules, it enhances the accuracy of text analysis tasks such as information retrieval, sentiment analysis, and document classification. This flexibility makes it an invaluable tool for researchers and developers who require precise control over how words are processed in their NLP applications.\n",
    "\n",
    "In summary, the RegexpStemmer class offers a powerful and adaptable approach to stemming in NLP, enabling users to tailor the stemming process to meet specific linguistic needs while improving the overall effectiveness of language processing tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import RegexpStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_stemmer = RegexpStemmer('ing$|s$|e$|able$', min=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'runn'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_stemmer.stem('running')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eat'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_stemmer.stem('eating')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SnowballStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SnowballStemmer is an advanced stemming algorithm used in Natural Language Processing (NLP) that improves upon the original Porter Stemmer, also known as Porter2. Developed by Martin Porter, the SnowballStemmer addresses some of the limitations found in earlier stemming algorithms by providing a more robust and consistent approach to reducing words to their base or root forms. This capability is essential for various NLP tasks, including information retrieval, text classification, and sentiment analysis.\n",
    "\n",
    "Key Features:\n",
    "\n",
    "1: Multi-Language Support: One of the standout features of the SnowballStemmer is its ability to handle multiple languages. It supports a wide range of languages including English, Spanish, French, German, and many others, making it a versatile tool for global applications.\n",
    "\n",
    "2: Improved Accuracy: The SnowballStemmer employs a more comprehensive set of rules for suffix removal compared to its predecessor. This results in more accurate stemming outcomes, reducing the likelihood of over-stemming or under-stemming—issues where distinct words are incorrectly reduced to the same stem or similar words are not grouped together.\n",
    "\n",
    "3: Customizability: Users can customize the stemming process by defining specific rules for different languages or datasets. This flexibility allows for better adaptation to the nuances of various linguistic contexts.\n",
    "\n",
    "Importance in NLP:\n",
    "\n",
    "The SnowballStemmer plays a crucial role in enhancing the performance of NLP applications by ensuring that different forms of a word are treated as equivalent. For instance, it effectively maps variations like \"running,\" \"ran,\" and \"runner\" to their common stem \"run.\" This normalization simplifies text data and improves search efficiency by allowing systems to retrieve relevant documents regardless of the specific word forms used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "snowball_stemmer = SnowballStemmer('english')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running-->run\n",
      "runner-->runner\n",
      "ran-->ran\n",
      "runs-->run\n",
      "easily-->easili\n",
      "fairly-->fair\n",
      "eating-->eat\n",
      "eat-->eat\n",
      "eater-->eater\n",
      "ate-->ate\n",
      "eats-->eat\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word + \"-->\" + snowball_stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('fairli', 'sporingli')"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemming.stem('fairly'), stemming.stem('sporingly')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('fairli', 'fairly', 'fair')"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemming.stem('fairly'),reg_stemmer.stem('fairly'), snowball_stemmer.stem('fairly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('sportingli', 'sportingly', 'sport')"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemming.stem('sportingly'),reg_stemmer.stem('sportingly'), snowball_stemmer.stem('sportingly')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lemmatization is a crucial technique in Natural Language Processing (NLP) that involves reducing words to their base or dictionary form, known as the \"lemma.\" Unlike stemming, which simply truncates words to their root forms without considering context or meaning, lemmatization takes into account the intended meaning and part of speech of a word. This process ensures that words with similar meanings are grouped together, facilitating a more accurate understanding of language.\n",
    "\n",
    "Understanding Lemmatization:\n",
    "\n",
    "In lemmatization, each word is analyzed in its context to determine its lemma. For instance, the word \"better\" is lemmatized to \"good,\" reflecting its meaning based on its use in a sentence. Similarly, verbs like \"running,\" \"ran,\" and \"runs\" are all reduced to their base form \"run.\" This method is particularly useful in applications where semantic accuracy is essential, such as chatbots, search engines, and information retrieval systems.\n",
    "\n",
    "Importance in NLP:\n",
    "\n",
    "Lemmatization enhances the effectiveness of various NLP tasks by providing a more nuanced approach to text normalization. By ensuring that different forms of a word are recognized as equivalent based on their meanings, it improves the performance of algorithms in tasks such as sentiment analysis, text classification, and machine translation. Although lemmatization can be more computationally intensive than stemming due to its reliance on dictionaries and morphological analysis, its accuracy makes it invaluable for applications that require a deep understanding of language.\n",
    "In summary, lemmatization plays a vital role in NLP by enabling systems to process language with greater precision. Its ability to accurately identify and group words based on their meanings underscores its significance in developing intelligent language processing applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'go'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize(\"going\", pos=\"n\")\n",
    "lemmatizer.lemmatize(\"going\", pos=\"a\")\n",
    "lemmatizer.lemmatize(\"going\", pos=\"v\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ['running', 'runner', 'programming', 'programs', 'ran', 'runs', 'easily', 'fairly', \"eating\", 'eat', 'eater', 'ate', 'eats']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running-->run\n",
      "runner-->runner\n",
      "programming-->program\n",
      "programs-->program\n",
      "ran-->run\n",
      "runs-->run\n",
      "easily-->easily\n",
      "fairly-->fairly\n",
      "eating-->eat\n",
      "eat-->eat\n",
      "eater-->eater\n",
      "ate-->eat\n",
      "eats-->eat\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word + \"-->\" + lemmatizer.lemmatize(word,pos='v'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Speech of Matin Luther King Jr \"I have a dream\"\n",
    "\n",
    "speech = \"\"\"I am happy to join with you today in what will go down in history as the greatest\n",
    "demonstration for freedom in the history of our nation.\n",
    "Five score years ago, a great American, in whose symbolic shadow we stand today, signed the\n",
    "Emancipation Proclamation. This momentous decree came as a great beacon light of hope to millions of\n",
    "Negro slaves who had been seared in the flames of withering injustice. It came as a joyous daybreak to\n",
    "end the long night of their captivity.\n",
    "But 100 years later, the Negro still is not free. There are those who are asking the devotees of Civil\n",
    "Rights: “When will you be satisfied?” We can never be satisfied as long as the Negro is the victim of the\n",
    "unspeakable horrors of police brutality. We can never be satisfied as long as our children are stripped of\n",
    "their selfhood and robbed of their dignity by signs stating “For whites only.” No, no we are not satisfied,\n",
    "and we will not be satisfied until “justice rolls down like waters and righteousness like a mighty stream.”\n",
    "I have a dream that one day on the red hills of Georgia, sons of former slaves and the sons of former\n",
    "slave owners will be able to sit down together at the table of brotherhood.\n",
    "I have a dream that one day, even the state of Mississippi, a state sweltering with the heat of injustice,\n",
    "sweltering with the heat of oppression, be transformed into an oasis of freedom and justice.\n",
    "I have a dream that my four little children will one day live in a nation where they will not be judged by\n",
    "the color of their skin but by the content of their character. I have a dream today.\n",
    "I have a dream that one day down in Alabama with its vicious racists, with its governor having his lips\n",
    "dripping with the words of interposition and nullification, one day right down in Alabama little black\n",
    "boys and black girls will be able to join hands with little white boys and white girls as sisters and\n",
    "brothers. I have a dream today.\n",
    "I have a dream that one day “every valley shall be exalted, every hill and mountain shall be made low,\n",
    "the rough places will be made plain, and the crooked places will be made straight, and the glory of the\n",
    "Lord shall be revealed, and all flesh shall see it together.”\n",
    "This is our hope, this is the faith that I go back to the South with. With this faith, we will be able to hew\n",
    "out of the mountain of despair, a stone of hope. With this faith, we will be able to transform the\n",
    "jangling discords of our nation into a beautiful symphony of brotherhood. With this faith we will be able\n",
    "to work together, to pray together, to struggle together, to go to jail together, to stand up for freedom\n",
    "together, knowing that we will be free one day. This will be the day. This will be the day when all of\n",
    "God’s children will be able to sing with new meaning:\n",
    "My country, ‘tis of thee, sweet land of liberty, of thee I sing.\n",
    "Land where my fathers died, land of the pilgrim’s pride,\n",
    "From every mountainside, let freedom ring!\n",
    "And if America is to be a great nation, this must become true.\n",
    "Video Transcript for Archival Research Catalog (ARC) Identifier 2602934\n",
    "National Archives and Records Administration www.archives.gov\n",
    "So let freedom ring from the prodigious hilltops of New Hampshire.\n",
    "Let freedom ring from the mighty mountains of New York.\n",
    "Let freedom ring from the heightening Alleghenies of Pennsylvania.\n",
    "Let freedom ring from the snowcapped Rockies of Colorado.\n",
    "Let freedom ring from the curvaceous slopes of California.\n",
    "But not only that. Let freedom ring from Stone Mountain of Georgia.\n",
    "Let freedom ring from Lookout Mountain of Tennessee.\n",
    "Let freedom ring from every hill and molehill of Mississippi.\n",
    "From every mountainside, let freedom ring.\n",
    "And when this happens, when we allow freedom ring, when we let it ring from every village and every\n",
    "hamlet, from every state and every city, we will be able to speed up that day when all of God’s children,\n",
    "black men and white men, Jews and Gentiles, Protestants and Catholics, will be able to join hands and\n",
    "sing in the words of the old Negro spiritual:\n",
    "Free at last! Free at last!\n",
    "Thank God Almighty, we are free at last.\n",
    "[Applause and singing]\n",
    "Speaker: On behalf of the National Committee on the March on Washington…\n",
    "Woman singing:\n",
    "Oh deep in my heart, I do believe, we shall overcome some day.\n",
    "White man work together, black man work together. We shall overcome some day!\n",
    "Oh, deep in my heart, I do believe, we shall overcome some day.\n",
    "Crowd singing:\n",
    "We’ll walk hand in hand, we’ll walk hand in hand some day!\n",
    "Oh, deep in my heart, I do believe.\n",
    "A. Philip Randolph: I think history was written today which will have its effect on coming generations,\n",
    "with respect to our democracy, with respect to our ideals, with respect to the great struggle of man,\n",
    "God, freedom, and human dignity.\n",
    "Narrator: There were many who praised this day and said that there had been a new awakening in the\n",
    "conscience of the nation. Others called it a national disgrace. In the wake of this day, more violence\n",
    "was to come, more hatred, but in the long history of man’s cruelty to man, this was a day of hope.\n",
    "Video Transcript for Archival Research Catalog (ARC) Identifier 2602934\n",
    "National Archives and Records Administration www.archives.gov\n",
    "Crowd singing:\n",
    "Freedom, freedom, freedom, freedom freedom!\n",
    "Freedom, freedom, freedom, freedom freedom!\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am happy to join with you today in what will go down in history as the greatest\n",
      "demonstration for freedom in the history of our nation.\n",
      "Five score years ago, a great American, in whose symbolic shadow we stand today, signed the\n",
      "Emancipation Proclamation. This momentous decree came as a great beacon light of hope to millions of\n",
      "Negro slaves who had been seared in the flames of withering injustice. It came as a joyous daybreak to\n",
      "end the long night of their captivity.\n",
      "But 100 years later, the Negro still is not free. There are those who are asking the devotees of Civil\n",
      "Rights: “When will you be satisfied?” We can never be satisfied as long as the Negro is the victim of the\n",
      "unspeakable horrors of police brutality. We can never be satisfied as long as our children are stripped of\n",
      "their selfhood and robbed of their dignity by signs stating “For whites only.” No, no we are not satisfied,\n",
      "and we will not be satisfied until “justice rolls down like waters and righteousness like a mighty stream.”\n",
      "I have a dream that one day on the red hills of Georgia, sons of former slaves and the sons of former\n",
      "slave owners will be able to sit down together at the table of brotherhood.\n",
      "I have a dream that one day, even the state of Mississippi, a state sweltering with the heat of injustice,\n",
      "sweltering with the heat of oppression, be transformed into an oasis of freedom and justice.\n",
      "I have a dream that my four little children will one day live in a nation where they will not be judged by\n",
      "the color of their skin but by the content of their character. I have a dream today.\n",
      "I have a dream that one day down in Alabama with its vicious racists, with its governor having his lips\n",
      "dripping with the words of interposition and nullification, one day right down in Alabama little black\n",
      "boys and black girls will be able to join hands with little white boys and white girls as sisters and\n",
      "brothers. I have a dream today.\n",
      "I have a dream that one day “every valley shall be exalted, every hill and mountain shall be made low,\n",
      "the rough places will be made plain, and the crooked places will be made straight, and the glory of the\n",
      "Lord shall be revealed, and all flesh shall see it together.”\n",
      "This is our hope, this is the faith that I go back to the South with. With this faith, we will be able to hew\n",
      "out of the mountain of despair, a stone of hope. With this faith, we will be able to transform the\n",
      "jangling discords of our nation into a beautiful symphony of brotherhood. With this faith we will be able\n",
      "to work together, to pray together, to struggle together, to go to jail together, to stand up for freedom\n",
      "together, knowing that we will be free one day. This will be the day. This will be the day when all of\n",
      "God’s children will be able to sing with new meaning:\n",
      "My country, ‘tis of thee, sweet land of liberty, of thee I sing.\n",
      "Land where my fathers died, land of the pilgrim’s pride,\n",
      "From every mountainside, let freedom ring!\n",
      "And if America is to be a great nation, this must become true.\n",
      "Video Transcript for Archival Research Catalog (ARC) Identifier 2602934\n",
      "National Archives and Records Administration www.archives.gov\n",
      "So let freedom ring from the prodigious hilltops of New Hampshire.\n",
      "Let freedom ring from the mighty mountains of New York.\n",
      "Let freedom ring from the heightening Alleghenies of Pennsylvania.\n",
      "Let freedom ring from the snowcapped Rockies of Colorado.\n",
      "Let freedom ring from the curvaceous slopes of California.\n",
      "But not only that. Let freedom ring from Stone Mountain of Georgia.\n",
      "Let freedom ring from Lookout Mountain of Tennessee.\n",
      "Let freedom ring from every hill and molehill of Mississippi.\n",
      "From every mountainside, let freedom ring.\n",
      "And when this happens, when we allow freedom ring, when we let it ring from every village and every\n",
      "hamlet, from every state and every city, we will be able to speed up that day when all of God’s children,\n",
      "black men and white men, Jews and Gentiles, Protestants and Catholics, will be able to join hands and\n",
      "sing in the words of the old Negro spiritual:\n",
      "Free at last! Free at last!\n",
      "Thank God Almighty, we are free at last.\n",
      "[Applause and singing]\n",
      "Speaker: On behalf of the National Committee on the March on Washington…\n",
      "Woman singing:\n",
      "Oh deep in my heart, I do believe, we shall overcome some day.\n",
      "White man work together, black man work together. We shall overcome some day!\n",
      "Oh, deep in my heart, I do believe, we shall overcome some day.\n",
      "Crowd singing:\n",
      "We’ll walk hand in hand, we’ll walk hand in hand some day!\n",
      "Oh, deep in my heart, I do believe.\n",
      "A. Philip Randolph: I think history was written today which will have its effect on coming generations,\n",
      "with respect to our democracy, with respect to our ideals, with respect to the great struggle of man,\n",
      "God, freedom, and human dignity.\n",
      "Narrator: There were many who praised this day and said that there had been a new awakening in the\n",
      "conscience of the nation. Others called it a national disgrace. In the wake of this day, more violence\n",
      "was to come, more hatred, but in the long history of man’s cruelty to man, this was a day of hope.\n",
      "Video Transcript for Archival Research Catalog (ARC) Identifier 2602934\n",
      "National Archives and Records Administration www.archives.gov\n",
      "Crowd singing:\n",
      "Freedom, freedom, freedom, freedom freedom!\n",
      "Freedom, freedom, freedom, freedom freedom!\n"
     ]
    }
   ],
   "source": [
    "print(speech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/jasper/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stopwords.words('dutch'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer = PorterStemmer()\n",
    "sentences = nltk.sent_tokenize(speech)\n",
    "type(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I am happy to join with you today in what will go down in history as the greatest\\ndemonstration for freedom in the history of our nation.', 'Five score years ago, a great American, in whose symbolic shadow we stand today, signed the\\nEmancipation Proclamation.', 'This momentous decree came as a great beacon light of hope to millions of\\nNegro slaves who had been seared in the flames of withering injustice.', 'It came as a joyous daybreak to\\nend the long night of their captivity.', 'But 100 years later, the Negro still is not free.', 'There are those who are asking the devotees of Civil\\nRights: “When will you be satisfied?” We can never be satisfied as long as the Negro is the victim of the\\nunspeakable horrors of police brutality.', 'We can never be satisfied as long as our children are stripped of\\ntheir selfhood and robbed of their dignity by signs stating “For whites only.” No, no we are not satisfied,\\nand we will not be satisfied until “justice rolls down like waters and righteousness like a mighty stream.”\\nI have a dream that one day on the red hills of Georgia, sons of former slaves and the sons of former\\nslave owners will be able to sit down together at the table of brotherhood.', 'I have a dream that one day, even the state of Mississippi, a state sweltering with the heat of injustice,\\nsweltering with the heat of oppression, be transformed into an oasis of freedom and justice.', 'I have a dream that my four little children will one day live in a nation where they will not be judged by\\nthe color of their skin but by the content of their character.', 'I have a dream today.', 'I have a dream that one day down in Alabama with its vicious racists, with its governor having his lips\\ndripping with the words of interposition and nullification, one day right down in Alabama little black\\nboys and black girls will be able to join hands with little white boys and white girls as sisters and\\nbrothers.', 'I have a dream today.', 'I have a dream that one day “every valley shall be exalted, every hill and mountain shall be made low,\\nthe rough places will be made plain, and the crooked places will be made straight, and the glory of the\\nLord shall be revealed, and all flesh shall see it together.”\\nThis is our hope, this is the faith that I go back to the South with.', 'With this faith, we will be able to hew\\nout of the mountain of despair, a stone of hope.', 'With this faith, we will be able to transform the\\njangling discords of our nation into a beautiful symphony of brotherhood.', 'With this faith we will be able\\nto work together, to pray together, to struggle together, to go to jail together, to stand up for freedom\\ntogether, knowing that we will be free one day.', 'This will be the day.', 'This will be the day when all of\\nGod’s children will be able to sing with new meaning:\\nMy country, ‘tis of thee, sweet land of liberty, of thee I sing.', 'Land where my fathers died, land of the pilgrim’s pride,\\nFrom every mountainside, let freedom ring!', 'And if America is to be a great nation, this must become true.', 'Video Transcript for Archival Research Catalog (ARC) Identifier 2602934\\nNational Archives and Records Administration www.archives.gov\\nSo let freedom ring from the prodigious hilltops of New Hampshire.', 'Let freedom ring from the mighty mountains of New York.', 'Let freedom ring from the heightening Alleghenies of Pennsylvania.', 'Let freedom ring from the snowcapped Rockies of Colorado.', 'Let freedom ring from the curvaceous slopes of California.', 'But not only that.', 'Let freedom ring from Stone Mountain of Georgia.', 'Let freedom ring from Lookout Mountain of Tennessee.', 'Let freedom ring from every hill and molehill of Mississippi.', 'From every mountainside, let freedom ring.', 'And when this happens, when we allow freedom ring, when we let it ring from every village and every\\nhamlet, from every state and every city, we will be able to speed up that day when all of God’s children,\\nblack men and white men, Jews and Gentiles, Protestants and Catholics, will be able to join hands and\\nsing in the words of the old Negro spiritual:\\nFree at last!', 'Free at last!', 'Thank God Almighty, we are free at last.', '[Applause and singing]\\nSpeaker: On behalf of the National Committee on the March on Washington…\\nWoman singing:\\nOh deep in my heart, I do believe, we shall overcome some day.', 'White man work together, black man work together.', 'We shall overcome some day!', 'Oh, deep in my heart, I do believe, we shall overcome some day.', 'Crowd singing:\\nWe’ll walk hand in hand, we’ll walk hand in hand some day!', 'Oh, deep in my heart, I do believe.', 'A. Philip Randolph: I think history was written today which will have its effect on coming generations,\\nwith respect to our democracy, with respect to our ideals, with respect to the great struggle of man,\\nGod, freedom, and human dignity.', 'Narrator: There were many who praised this day and said that there had been a new awakening in the\\nconscience of the nation.', 'Others called it a national disgrace.', 'In the wake of this day, more violence\\nwas to come, more hatred, but in the long history of man’s cruelty to man, this was a day of hope.', 'Video Transcript for Archival Research Catalog (ARC) Identifier 2602934\\nNational Archives and Records Administration www.archives.gov\\nCrowd singing:\\nFreedom, freedom, freedom, freedom freedom!', 'Freedom, freedom, freedom, freedom freedom!']\n"
     ]
    }
   ],
   "source": [
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remove stopwords and then apply the stemming\n",
    "\n",
    "for i in range(len(sentences)):\n",
    "    words = nltk.word_tokenize(sentences[i])\n",
    "    words = [stemmer.stem(word)for word in words if word not in set(stopwords.words('english'))]\n",
    "    sentences[i] = \" \".join(words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i happi join today go histori greatest demonstr freedom histori nation .', 'five score year ago , great american , whose symbol shadow stand today , sign emancip proclam .', 'thi moment decre came great beacon light hope million negro slave sear flame wither injustic .', 'it came joyou daybreak end long night captiv .', 'but 100 year later , negro still free .', 'there ask devote civil right : “ when satisfi ? ” we never satisfi long negro victim unspeak horror polic brutal .', 'we never satisfi long children strip selfhood rob digniti sign state “ for white only. ” no , satisfi , satisfi “ justic roll like water righteous like mighti stream. ” i dream one day red hill georgia , son former slave son former slave owner abl sit togeth tabl brotherhood .', 'i dream one day , even state mississippi , state swelter heat injustic , swelter heat oppress , transform oasi freedom justic .', 'i dream four littl children one day live nation judg color skin content charact .', 'i dream today .', 'i dream one day alabama viciou racist , governor lip drip word interposit nullif , one day right alabama littl black boy black girl abl join hand littl white boy white girl sister brother .', 'i dream today .', 'i dream one day “ everi valley shall exalt , everi hill mountain shall made low , rough place made plain , crook place made straight , glori lord shall reveal , flesh shall see together. ” thi hope , faith i go back south .', 'with faith , abl hew mountain despair , stone hope .', 'with faith , abl transform jangl discord nation beauti symphoni brotherhood .', 'with faith abl work togeth , pray togeth , struggl togeth , go jail togeth , stand freedom togeth , know free one day .', 'thi day .', 'thi day god ’ children abl sing new mean : my countri , ‘ ti thee , sweet land liberti , thee i sing .', 'land father die , land pilgrim ’ pride , from everi mountainsid , let freedom ring !', 'and america great nation , must becom true .', 'video transcript archiv research catalog ( arc ) identifi 2602934 nation archiv record administr www.archives.gov so let freedom ring prodigi hilltop new hampshir .', 'let freedom ring mighti mountain new york .', 'let freedom ring heighten allegheni pennsylvania .', 'let freedom ring snowcap rocki colorado .', 'let freedom ring curvac slope california .', 'but .', 'let freedom ring stone mountain georgia .', 'let freedom ring lookout mountain tennesse .', 'let freedom ring everi hill molehil mississippi .', 'from everi mountainsid , let freedom ring .', 'and happen , allow freedom ring , let ring everi villag everi hamlet , everi state everi citi , abl speed day god ’ children , black men white men , jew gentil , protest cathol , abl join hand sing word old negro spiritu : free last !', 'free last !', 'thank god almighti , free last .', '[ applaus sing ] speaker : on behalf nation committe march washington… woman sing : oh deep heart , i believ , shall overcom day .', 'white man work togeth , black man work togeth .', 'we shall overcom day !', 'oh , deep heart , i believ , shall overcom day .', 'crowd sing : we ’ walk hand hand , ’ walk hand hand day !', 'oh , deep heart , i believ .', 'a. philip randolph : i think histori written today effect come gener , respect democraci , respect ideal , respect great struggl man , god , freedom , human digniti .', 'narrat : there mani prais day said new awaken conscienc nation .', 'other call nation disgrac .', 'in wake day , violenc come , hatr , long histori man ’ cruelti man , day hope .', 'video transcript archiv research catalog ( arc ) identifi 2602934 nation archiv record administr www.archives.gov crowd sing : freedom , freedom , freedom , freedom freedom !', 'freedom , freedom , freedom , freedom freedom !']\n"
     ]
    }
   ],
   "source": [
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i happi join today go histori greatest demonstr freedom histori nation .',\n",
       " 'five score year ago , great american , whose symbol shadow stand today , sign emancip proclam .',\n",
       " 'thi moment decre came great beacon light hope million negro slave sear flame wither injustic .',\n",
       " 'it came joyou daybreak end long night captiv .',\n",
       " 'but 100 year later , negro still free .',\n",
       " 'there ask devote civil right : “ when satisfi ? ” we never satisfi long negro victim unspeak horror polic brutal .',\n",
       " 'we never satisfi long children strip selfhood rob digniti sign state “ for white only. ” no , satisfi , satisfi “ justic roll like water righteous like mighti stream. ” i dream one day red hill georgia , son former slave son former slave owner abl sit togeth tabl brotherhood .',\n",
       " 'i dream one day , even state mississippi , state swelter heat injustic , swelter heat oppress , transform oasi freedom justic .',\n",
       " 'i dream four littl children one day live nation judg color skin content charact .',\n",
       " 'i dream today .',\n",
       " 'i dream one day alabama viciou racist , governor lip drip word interposit nullif , one day right alabama littl black boy black girl abl join hand littl white boy white girl sister brother .',\n",
       " 'i dream today .',\n",
       " 'i dream one day “ everi valley shall exalt , everi hill mountain shall made low , rough place made plain , crook place made straight , glori lord shall reveal , flesh shall see together. ” thi hope , faith i go back south .',\n",
       " 'with faith , abl hew mountain despair , stone hope .',\n",
       " 'with faith , abl transform jangl discord nation beauti symphoni brotherhood .',\n",
       " 'with faith abl work togeth , pray togeth , struggl togeth , go jail togeth , stand freedom togeth , know free one day .',\n",
       " 'thi day .',\n",
       " 'thi day god ’ children abl sing new mean : my countri , ‘ ti thee , sweet land liberti , thee i sing .',\n",
       " 'land father die , land pilgrim ’ pride , from everi mountainsid , let freedom ring !',\n",
       " 'and america great nation , must becom true .',\n",
       " 'video transcript archiv research catalog ( arc ) identifi 2602934 nation archiv record administr www.archives.gov so let freedom ring prodigi hilltop new hampshir .',\n",
       " 'let freedom ring mighti mountain new york .',\n",
       " 'let freedom ring heighten allegheni pennsylvania .',\n",
       " 'let freedom ring snowcap rocki colorado .',\n",
       " 'let freedom ring curvac slope california .',\n",
       " 'but .',\n",
       " 'let freedom ring stone mountain georgia .',\n",
       " 'let freedom ring lookout mountain tennesse .',\n",
       " 'let freedom ring everi hill molehil mississippi .',\n",
       " 'from everi mountainsid , let freedom ring .',\n",
       " 'and happen , allow freedom ring , let ring everi villag everi hamlet , everi state everi citi , abl speed day god ’ children , black men white men , jew gentil , protest cathol , abl join hand sing word old negro spiritu : free last !',\n",
       " 'free last !',\n",
       " 'thank god almighti , free last .',\n",
       " '[ applaus sing ] speaker : on behalf nation committe march washington… woman sing : oh deep heart , i believ , shall overcom day .',\n",
       " 'white man work togeth , black man work togeth .',\n",
       " 'we shall overcom day !',\n",
       " 'oh , deep heart , i believ , shall overcom day .',\n",
       " 'crowd sing : we ’ walk hand hand , ’ walk hand hand day !',\n",
       " 'oh , deep heart , i believ .',\n",
       " 'a. philip randolph : i think histori written today effect come gener , respect democraci , respect ideal , respect great struggl man , god , freedom , human digniti .',\n",
       " 'narrat : there mani prais day said new awaken conscienc nation .',\n",
       " 'other call nation disgrac .',\n",
       " 'in wake day , violenc come , hatr , long histori man ’ cruelti man , day hope .',\n",
       " 'video transcript archiv research catalog ( arc ) identifi 2602934 nation archiv record administr www.archives.gov crowd sing : freedom , freedom , freedom , freedom freedom !',\n",
       " 'freedom , freedom , freedom , freedom freedom !']"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "snowball_stemmer = SnowballStemmer('english')# for English language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(sentences)):\n",
    "    words = nltk.word_tokenize(sentences[i])\n",
    "    words = [snowball_stemmer.stem(word)for word in words if word not in set(stopwords.words('english'))]\n",
    "    sentences[i] = \" \".join(words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['happi join today go histori greatest demonstr freedom histori nation .',\n",
       " 'five score year ago , great american , whose symbol shadow stand today , sign emancip proclam .',\n",
       " 'thi moment decr came great beacon light hope million negro slave sear flame wither injust .',\n",
       " 'came joyou daybreak end long night captiv .',\n",
       " '100 year later , negro still free .',\n",
       " 'ask devot civil right : “ satisfi ? ” never satisfi long negro victim unspeak horror polic brutal .',\n",
       " 'never satisfi long children strip selfhood rob digniti sign state “ white . ” , satisfi , satisfi “ justic roll like water righteous like mighti stream . ” dream one day red hill georgia , son former slave son former slave owner abl sit togeth tabl brotherhood .',\n",
       " 'dream one day , even state mississippi , state swelter heat injust , swelter heat oppress , transform oasi freedom justic .',\n",
       " 'dream four littl children one day live nation judg color skin content charact .',\n",
       " 'dream today .',\n",
       " 'dream one day alabama viciou racist , governor lip drip word interposit nullif , one day right alabama littl black boy black girl abl join hand littl white boy white girl sister brother .',\n",
       " 'dream today .',\n",
       " 'dream one day “ everi valley shall exalt , everi hill mountain shall made low , rough place made plain , crook place made straight , glori lord shall reveal , flesh shall see togeth . ” thi hope , faith go back south .',\n",
       " 'faith , abl hew mountain despair , stone hope .',\n",
       " 'faith , abl transform jangl discord nation beauti symphoni brotherhood .',\n",
       " 'faith abl work togeth , pray togeth , struggl togeth , go jail togeth , stand freedom togeth , know free one day .',\n",
       " 'thi day .',\n",
       " 'thi day god ’ children abl sing new mean : countri , ‘ ti thee , sweet land liberti , thee sing .',\n",
       " 'land father die , land pilgrim ’ pride , everi mountainsid , let freedom ring !',\n",
       " 'america great nation , must becom true .',\n",
       " 'video transcript archiv research catalog ( arc ) identifi 2602934 nation archiv record administr www.archives.gov let freedom ring prodigi hilltop new hampshir .',\n",
       " 'let freedom ring mighti mountain new york .',\n",
       " 'let freedom ring heighten allegheni pennsylvania .',\n",
       " 'let freedom ring snowcap rocki colorado .',\n",
       " 'let freedom ring curvac slope california .',\n",
       " '.',\n",
       " 'let freedom ring stone mountain georgia .',\n",
       " 'let freedom ring lookout mountain tenness .',\n",
       " 'let freedom ring everi hill molehil mississippi .',\n",
       " 'everi mountainsid , let freedom ring .',\n",
       " 'happen , allow freedom ring , let ring everi villag everi hamlet , everi state everi citi , abl speed day god ’ children , black men white men , jew gentil , protest cathol , abl join hand sing word old negro spiritu : free last !',\n",
       " 'free last !',\n",
       " 'thank god almighti , free last .',\n",
       " '[ applaus sing ] speaker : behalf nation committ march washington… woman sing : oh deep heart , believ , shall overcom day .',\n",
       " 'white man work togeth , black man work togeth .',\n",
       " 'shall overcom day !',\n",
       " 'oh , deep heart , believ , shall overcom day .',\n",
       " 'crowd sing : ’ walk hand hand , ’ walk hand hand day !',\n",
       " 'oh , deep heart , believ .',\n",
       " 'a. philip randolph : think histori written today effect come gener , respect democraci , respect ideal , respect great struggl man , god , freedom , human digniti .',\n",
       " 'narrat : mani prai day said new awaken conscienc nation .',\n",
       " 'call nation disgrac .',\n",
       " 'wake day , violenc come , hatr , long histori man ’ cruelti man , day hope .',\n",
       " 'video transcript archiv research catalog ( arc ) identifi 2602934 nation archiv record administr www.archives.gov crowd sing : freedom , freedom , freedom , freedom freedom !',\n",
       " 'freedom , freedom , freedom , freedom freedom !']"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
